<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Anonymous Rebuttal for APLDM</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Anonymous Rebuttal for APLDM</h1>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                  <!-- acknowledgement -->
                  <h2 class="title is-3"> Acknowledgement </h2>
                  <div class="content has-text-justified">
                      <p> We would like to sincerely thank the reviewers for taking time out of their busy schedules to provide valuable and insightful feedback on our work. These suggestions are greatly appreciated. </p>
                  </div>
                  <!-- END acknowledgement -->
                  
                  <!-- Preface -->
                      <h2 class="title is-3"> Preface </h2>
                      <div class="content has-text-justified">
                        <p style="font-weight: bold;"> On this webpage, we will provide detailed answers to the reviewers' questions regarding APLDM. </p>
                        <p> If necessary, the explanations and experiments in this page will be added to the paper. </p>
                        <p> Let us use the notation from the paper of APLDM: let \( \boldsymbol{z}_t \) represent the latent representation at step \( t \), and \( \tilde{\boldsymbol{z}}_t = \text{PFSA}(\boldsymbol{z}_t) \). The default value of \( T_0 \) is set to 50. </p>
                      </div>
                  <!-- END Preface -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/anonymous-rebuttal-123/APLDM-rebuttal" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span> Anonymous Github Page </span>
                  </a>
                  <br>
                  <br>
                  </span>
                  <!-- END Github link -->
                  
                  <!-- catalogue -->
                  <h2 class="title is-3"> Catalogue </h2>
                  <div class="content has-text-justified">
                      <p style="font-size: 24px;"><a href="#section1"> 1. Displaying Intermediate Generation Results of APLDM </a></p>
                      <p style="font-size: 24px;"><a href="#section2"> 2. How Does PFSA Work? </a></p>
                        <p style="font-size: 16px; text-indent: 2em;"><a href="#section2.1"> 2.1 PFSA Clusters Tokens of Latent Representations </a></p>
                        <p style="font-size: 16px; text-indent: 2em;"><a href="#section2.2"> 2.2 PFSA Adjusts the Variance and High-Frequency Signal Intensity of Latent Representations </a></p>
                      <p style="font-size: 24px;"><a href="#section3"> 3. Comparison with HiDiffusion & SDXL+BSRGAN </a></p>
                      <p style="font-size: 24px;"><a href="#section4"> 4. Attentive Guidance is Effective in Other Generation Frameworks </a></p>
                      <p style="font-size: 24px;"><a href="#section5"> 5. Comparison & Ablation Experiments Based on StableDiffusion2.1 </a></p>
                        <p style="font-size: 16px; text-indent: 2em;"><a href="#section5.1"> 5.1 Comparison Experiments </a></p>
                        <p style="font-size: 16px; text-indent: 2em;"><a href="#section5.2"> 5.2 Ablation Experiments </a></p>
                  </div>
                  <!-- END catalogue -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Question 1 -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 id="section1"><h2 class="title is-3"> 1. Displaying Intermediate Generation Results of APLDM </h2></h2>
      
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
           <!-- Your image here -->
           <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
           <h2 class="subtitle has-text-centered"> First image description. </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
            <h2 class="subtitle has-text-centered"> Second image description. </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
            <h2 class="subtitle has-text-centered"> Third image description. </h2>
         </div>
         <div class="item">
          <!-- Your image here -->
          <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered"> Fourth image description. </h2>
        </div>
      </div>
     </div>
    </div>
  </div>
</section>
<!-- End Question 1 -->


<!-- Question 2 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 id="section2"><h2 class="title is-3"> 2. How Does PFSA Work? </h2></h2>
      <div class="content has-text-justified">
        <p> The role of PFSA is manifested in two aspects: </p>
        <p><i><b> (i) clustering effect: </b></i> it has the ability to cluster tokens into several categories. </p>
        <p><i><b> (ii) adjusting the variance and intensity across different frequency bands: </b></i> during the early and middle stages of denoising, PFSA amplifies the high-frequency signal intensity of the latent representation,
          and increases the variance, while in the later stages of denoising, it reduces the high-frequency signal intensity, and decreases the variance; </p>
      </div>

      <h2 id="section2.1"><h2 class="title is-4"> 2.1 PFSA Clusters Tokens of Latent Representations </h2></h2>
      <div class="content has-text-justified">
        <p>
          To illustrate the clustering effect of PFSA, we calculated the deviation of tokens' mean (DTM) of the latent representation \( \boldsymbol{z}_t \) and \( \tilde{\boldsymbol{z}}_t \).
          Specifically, let \( \boldsymbol{z}_t \in \mathbb{R}^{h \times w \times c} \), and \( \boldsymbol{Z}_t = \text{Flatten}(z_t) = [\boldsymbol{y}_{t1}, \dots, \boldsymbol{y}_{tN}] \in \mathbb{R}^{N \times c} \), where \( N = h \times w \).
          The DTM is computed as: $$ \text{DTM} =  [\text{mean}(\boldsymbol{y}_{ti}) - \text{mean}(\boldsymbol{Z}_t) \; \text{for} \; i = 1, \dots, N] $$
          The results are shown in the figure below:
        </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 70%; height: auto;">
          <figcaption style="font-size: 0.9em; color: gray;">
            The first and second columns: Visualization of DTM plotted according to token indexes for large \( t \).  
            The third and fourth columns: Heatmaps of the DTM.  
            The fifth column: The corresponding generated RGB images.
          </figcaption>
        </figure>
        <p>
          From the images in the first and second columns, it can be observed that after the application of PFSA, the DTM of the latent representation exhibits distinct stripes, indicating that PFSA has clustered the tokens into several categories.
          From the third and fourth columns, it is evident that when \( t \) is smaller, the semantics of the latent representation become clearer, and the clustering effect of PFSA is more straightforward, and it is clearly observable that PFSA has clustered semantically related tokens.
        </p>
        <p>
          During the process of generating images, the semantics of the tokens are continually reinforced. We hypothesize that PFSA enhances the structural consistency of the latent representation by clustering semantically related tokens.
        </p>
      </div>
      
      <h2 id="section2.2"><h2 class="title is-4"> 2.2 PFSA Adjusts the Variance and High-Frequency Signal Intensity of Latent Representations </h2></h2>
      <div class="content has-text-justified">
        <p>
          We performed Fourier transforms on both \( \tilde{\boldsymbol{z}}_t \) and \( \boldsymbol{z}_t \), and calculated the mean of the standard deviations across their channels, as shown in the figure below:
        </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 70%; height: auto;">
        </figure>
        <p> It can be observed that the effect of PFSA can be divided into three phases:
          (<b> i </b>) from \( t = 49 \) to \( t = 46 \), PFSA suppresses the high-frequency signals of the latent representation;
          (<b> ii </b>) from \( t = 45 \) to \( t = 29 \), PFSA amplifies the high-frequency signals of the latent representation;
          and (<b> iii </b>) from \( t = 28 \) to \( t = 0 \), PFSA once again suppresses the high-frequency signals of the latent representation.
        </p>
        <p>
          In the first phase, it is evident that PFSA significantly alters the frequency distribution of the latent representation, particularly the intensity distribution of low-frequency signals.
          We hypothesize that this alteration may be the reason PFSA could lead to structural errors during the first phase.
        </p>
        <p>
          The second phase is the main phase where Attentive Guidance takes effect. During this phase, PFSA amplifies the high-frequency components of the latent representation.
          We hypothesize that this is the reason Attentive Guidance enables the generated images to exhibit richer details and colors, as shown in Figures 6 and 7 of the paper.
        </p>
        <p>
          In the third phase, it can be observed that the curve becomes smooth at \( t = 29 \), at which point the low-frequency components of the latent representation have been largely stabilized.
          Therefore, the effect of Attentive Guidance becomes limited at this stage, as shown in Figure 9 of the paper.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Question 2 -->


<!-- Question 3 -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 id="section3"><h2 class="title is-3"> 3. Comparison with HiDiffusion & SDXL+BSRGAN </h2></h2>
      <p> In this section, we use SDXL as the pre-trained model to compare APLDM with HiDiffusion and SDXL+BSRGAN (where SDXL generates low-resolution images, followed by BSRGAN for super-resolution). </p>
      
    </div>
  </div>
</section>
<!-- End Question 3 -->


<!-- Question 4 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 id="section4"><h2 class="title is-3"> 4. Attentive Guidance is Effective in Other Generation Frameworks </h2></h2>
      <p>  </p>
      
    </div>
  </div>
</section>
<!-- End Question 4 -->


<!-- Question 5 -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 id="section5"><h2 class="title is-3"> 5. Comparison & Ablation Experiments Based on StableDiffusion2.1 </h2></h2>
      <div class="content has-text-justified">
        <p> In this section, we analyze APLDM based on Stable Diffusion 2.1 (SD2.1). </p>
      </div>
      <h2 id="section5.1"><h2 class="title is-4"> 5.1 Comparison Experiments </h2></h2>
      <div class="content has-text-justified">
        <p> In this section, considering that DemoFusion and AccDiffusion only have open-source code based on SDXL, we conducted comparisons with ScaleCrafter and UpsampleGuidance (UG). </p>
        <p> Considering that SD2.1 is trained at the resolution of \( 512 \times 512 \), we conduct tests at four resolutions: \( 1536 \times 1536 \), \( 1024 \times 2048 \), \( 2048 \times 1024 \), and \( 2048 \times 2048 \). The results are shown in the table below: </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 40%; height: auto;">
        </figure>
        <p> As shown in the table above, APLDM still demonstrates superior performance on SD2.1. </p>
        <p>From the qualitative comparison in the figure below, it is evident that the images synthesized by APLDM exhibit better structural consistency. </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 70%; height: auto;">
        </figure>
      </div>
      
      <h2 id="section5.2"><h2 class="title is-4"> 5.2 Ablation Experiments </h2></h2>
      <div class="content has-text-justified">
        <p> In this section, we conduct an ablation study on Attentive Guidance using SD2.1 as the pre-trained model. </p>
        <p> The quantitative ablation analysis results of Attentive Guidance are shown in Table B. As can be seen from the table, even when using SD2.1 as the pre-trained model, Attentive Guidance still improves the quality of the generated images, demonstrating its generalization ability. </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 40%; height: auto;">
        </figure>
        <p> The qualitative ablation analysis results are shown in Figure E. As seen in Figure E, the use of Attentive Guidance results in richer image details and colors, further demonstrating the versatility of Attentive Guidance. </p>
        <figure style="text-align: center;">
          <img src="static/images/carousel4.jpg" alt="frequency_analysis_1" style="max-width: 70%; height: auto;">
        </figure>
      </div>
    </div>
  </div>
</section>
<!-- End Question 5 -->





























  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
